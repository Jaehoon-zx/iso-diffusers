{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0003, grad_fn=<DivBackward0>)\n",
      "tensor(0.0552, grad_fn=<DivBackward0>)\n",
      "tensor(-9.1619e-05)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.autograd.functional as A\n",
    "\n",
    "\n",
    "def stereographic_proj(x, device):\n",
    "    # R x S^(n-1) -> R x R^(n-1)\n",
    "    bs = x.shape[0]\n",
    "    x = x.flatten(1)\n",
    "    r = (x**2).sum(1).sqrt().unsqueeze(1)\n",
    "\n",
    "    return torch.cat((r, (1/(r - x[:,-1:])) * x[:,:-1]), dim=-1)\n",
    "\n",
    "def inv_stereographic_proj(t, shape ,device):\n",
    "    #  R x R^(n-1) --> R x S^(n-1)\n",
    "    t = t.flatten(1)\n",
    "    r, t = t[:,:1], t[:,1:]\n",
    "    t_norm_sq = (t ** 2).sum(1).unsqueeze(1)\n",
    "\n",
    "    result = r * torch.cat((2 * t, t_norm_sq - 1), dim=-1) / (t_norm_sq + 1)\n",
    "\n",
    "    return result.reshape(shape)\n",
    "\n",
    "def riemmanian_metric(t, device):\n",
    "    # Riemmanian metric in stereographic coordinates\n",
    "    r, t = t[:,:1], t[:,1:]\n",
    "    t_norm_sq = (t ** 2).sum()\n",
    "\n",
    "    G_t = 4 * r ** 4/ (t_norm_sq + r ** 2) ** 2 * torch.ones_like(t)\n",
    "    G_r = torch.ones((G_t.shape[0], 1), device=device)\n",
    "\n",
    "    return torch.cat((G_r, G_t), dim=-1)\n",
    "\n",
    "def isometry_loss(f, x, timesteps, device):\n",
    "    bs = x.shape[0]\n",
    "    t = stereographic_proj(x, device=device)\n",
    "    G = riemmanian_metric(t, device=device)\n",
    "\n",
    "    u = torch.randn_like(t, device=device)\n",
    "    v = (1/G * u).reshape(x.shape)\n",
    "    Ju = A.jvp(lambda t: f(inv_stereographic_proj(t, x.shape, device), timesteps)[1], t, 1/G * u, create_graph=True)[1] \n",
    "    JTJu = A.vjp(lambda t: f(inv_stereographic_proj(t, x.shape ,device), timesteps)[1], t, Ju, create_graph=True)[1]\n",
    "\n",
    "    TrG = torch.sum(Ju.view(bs, -1) ** 2, dim=1).mean()\n",
    "    TrG2 = torch.sum(JTJu.view(bs, -1) ** 2, dim=1).mean()\n",
    "\n",
    "    isometry_loss = TrG2 / TrG ** 2\n",
    "\n",
    "    return isometry_loss\n",
    "\n",
    "def isometry_loss_test(f, x, timesteps, device):\n",
    "    bs = x.shape[0]\n",
    "    # t = stereographic_proj(x)\n",
    "    # G = riemmanian_metric(t)\n",
    "\n",
    "    u = torch.randn_like(x, device=device)\n",
    "    Ju = A.jvp(lambda t: f(t, timesteps)[1], x, u, create_graph=True)[1] \n",
    "    JTJu = A.vjp(lambda t: f(t, timesteps)[1], x, Ju, create_graph=True)[1]\n",
    "\n",
    "    TrG = torch.sum(Ju.view(bs, -1) ** 2, dim=1).mean()\n",
    "    TrG2 = torch.sum(JTJu.view(bs, -1) ** 2, dim=1).mean()\n",
    "\n",
    "    isometry_loss = TrG2 / TrG ** 2\n",
    "\n",
    "    return isometry_loss\n",
    "\n",
    "def model(x, timesteps):\n",
    "     \n",
    "    y = stereographic_proj(x, 'cpu')\n",
    "    # y = inv_stereographic_proj(x)\n",
    "    # y = x\n",
    "\n",
    "    return (x,y)\n",
    "\n",
    "\n",
    "x = torch.rand((8, 3, 128, 128))\n",
    "iso_loss = isometry_loss(model, x, 1, 'cpu')\n",
    "print(iso_loss)\n",
    "\n",
    "iso_loss_test = isometry_loss_test(model, x, 1, 'cpu')\n",
    "print(iso_loss_test)\n",
    "\n",
    "t = stereographic_proj(x, 'cpu')\n",
    "y = inv_stereographic_proj(t, x.shape, 'cpu')\n",
    "\n",
    "print((x-y).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "pic should be 2/3 dimensional. Got 1 dimensions.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m3\u001b[39m])\n\u001b[1;32m      6\u001b[0m y \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(x)\n\u001b[0;32m----> 7\u001b[0m z \u001b[39m=\u001b[39m torchvision\u001b[39m.\u001b[39;49mtransforms\u001b[39m.\u001b[39;49mToTensor()(x)\n\u001b[1;32m      9\u001b[0m \u001b[39mprint\u001b[39m(z)\n",
      "File \u001b[0;32m~/anaconda3/envs/diffusers/lib/python3.10/site-packages/torchvision/transforms/transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, pic):\n\u001b[1;32m    130\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[39m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[39m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mto_tensor(pic)\n",
      "File \u001b[0;32m~/anaconda3/envs/diffusers/lib/python3.10/site-packages/torchvision/transforms/functional.py:143\u001b[0m, in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpic should be PIL Image or ndarray. Got \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(pic)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    142\u001b[0m \u001b[39mif\u001b[39;00m _is_numpy(pic) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_numpy_image(pic):\n\u001b[0;32m--> 143\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpic should be 2/3 dimensional. Got \u001b[39m\u001b[39m{\u001b[39;00mpic\u001b[39m.\u001b[39mndim\u001b[39m}\u001b[39;00m\u001b[39m dimensions.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    145\u001b[0m default_float_dtype \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mget_default_dtype()\n\u001b[1;32m    147\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(pic, np\u001b[39m.\u001b[39mndarray):\n\u001b[1;32m    148\u001b[0m     \u001b[39m# handle numpy array\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: pic should be 2/3 dimensional. Got 1 dimensions."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "x = np.array()\n",
    "y = torch.tensor(x)\n",
    "z = torchvision.transforms.ToTensor()(x)\n",
    "\n",
    "print(z)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
