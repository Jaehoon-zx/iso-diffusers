{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "torch.Size([64, 1, 1, 1])\n",
      "0.8282437324523926\n",
      "torch.Size([64, 1, 1, 1])\n",
      "10.823099136352539\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import lpips\n",
    "import time\n",
    "import dnnlib\n",
    "import pickle\n",
    "import piqa\n",
    "\n",
    "from torchmetrics.image.lpip import LearnedPerceptualImagePatchSimilarity\n",
    "lpips2 = LearnedPerceptualImagePatchSimilarity(net_type='vgg')\n",
    "\n",
    "# Define the batch size for loading data in mini-batches\n",
    "batch_size = 64\n",
    "\n",
    "# Transforms to apply to the data\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),  # Normalize the pixel values to [-1, 1]\n",
    "    transforms.Resize(256),\n",
    "])\n",
    "\n",
    "def open_file_or_url(file_or_url):\n",
    "    if dnnlib.util.is_url(file_or_url):\n",
    "        return dnnlib.util.open_url(file_or_url, cache_dir='.stylegan2-cache')\n",
    "    return open(file_or_url, 'rb')\n",
    "\n",
    "def load_pkl(file_or_url):\n",
    "    with open_file_or_url(file_or_url) as file:\n",
    "        return pickle.load(file, encoding='latin1')\n",
    "\n",
    "# Download and load the training set\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Download and load the test set\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train_iterator = iter(train_loader)\n",
    "images, labels = next(train_iterator)\n",
    "images2, labels2 = next(train_iterator)\n",
    "\n",
    "start = time.time()\n",
    "loss_fn_alex = lpips.LPIPS(net = 'alex', verbose = False)\n",
    "dist = loss_fn_alex(images, images2)\n",
    "print(dist.shape)\n",
    "print(time.time() - start)\n",
    "\n",
    "start = time.time()\n",
    "dist2 = lpips2(images, images2)\n",
    "print(dist.shape)\n",
    "print(time.time() - start)\n",
    "\n",
    "# distance_measure = load_pkl('https://nvlabs-fi-cdn.nvidia.com/stylegan/networks/metrics/vgg16_zhang_perceptual.pkl')\n",
    "# dist = distance_measure.get_output_for(images, images2)\n",
    "# dist = (lpips_t0 - lpips_t1).square().sum(1) / epsilon ** 2\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
